---
- name: Configure | Check if etcd cluster is healthy
  shell: "/usr/bin/etcdctl --ca-file /etc/kubernetes/pki/etcd/ca.pem --cert-file /etc/kubernetes/pki/etcd/client.pem --key-file /etc/kubernetes/pki/etcd/client-key.pem --peers https://{{ ansible_br_mgmt.ipv4.address }}:2379 cluster-health | grep -q 'cluster is healthy'"
  register: etcd_cluster_is_healthy
  ignore_errors: true
  changed_when: false
  check_mode: no
  until: etcd_cluster_is_healthy.rc == 0
  retries: 10
  delay: 5

- name: Stop etcd-member service on all etcd nodes
  become: yes
  service: name=etcd.service state=stopped

- name: Get local backup files list
  become: yes
  find:
    path: "{{ etcd_backup_local_root_dir }}"
    patterns: '*.tgz'
  register: local_backup_files

- name: Abort if no local etcd backups are found
  fail:
    msg: "No local etcd backup files found in {{ etcd_backup_local_root_dir }}"
  when: local_backup_files.files | length == 0

- name: Set etcd_backup_latest_file fact
  set_fact:
    etcd_backup_latest_file: "{{ local_backup_files.files | sort(attribute='mtime', reverse=true) | map(attribute='path') | first }}"

- name: Abort if etcd_backup_latest_file is not the same across all etcd nodes
  fail:
    msg: "etcd_backup_latest_file is not the same across all etcd nodes"
  when: (ansible_play_hosts | map('extract', hostvars, 'etcd_backup_latest_file') | list | unique | length) != 1
  run_once: true

- name: Check available disk space for etcd restore
  shell: df --output=avail -k {{ etcd_data_dir }} | tail -n 1
  register: local_avail_disk_space

- name: Check the uncompressed size of etcd backup
  become: yes
  shell: tar tzvf {{ etcd_backup_latest_file }} | awk '{s+=$3} END{print (s/1024)}'
  register: etcd_backup_uncompressed_size

- name: Abort if insufficient disk space for etcd restore
  fail:
    msg: >
      {{ etcd_backup_uncompressed_size.stdout | int * 3 }} KB disk space required for etcd restore, but
      {{ local_avail_disk_space.stdout }} KB available.
  when: (etcd_backup_uncompressed_size.stdout | int * 3) > (local_avail_disk_space.stdout | int)

#- name: Unarchive the latest etcd backup file {{ etcd_backup_latest_file }} on each ectd node
#  become: yes
#  unarchive:
#    src: "{{ etcd_backup_latest_file }}"
#    dest: "{{ etcd_backup_local_root_dir }}"
#    remote_src: yes

- name: Unarchive the latest etcd backup file {{ etcd_backup_latest_file }} on each ectd node
  become: yes
  unarchive:
    src: "{{ etcd_backup_latest_file }}"
    dest: "/root/."
    remote_src: yes

- name: Set etcd_backup_latest_dir fact
  set_fact:
    etcd_backup_latest_dir: "{{ etcd_backup_latest_file.split('.')[0] }}"

- name: Remove Obselate ETCD Member Directory
  file:
    path: "{{ item }}"
    state: absent
  with_items:
    - /var/lib/etcd

- name: Create etcd v3 data backup file
  become: yes
  # https://coreos.com/etcd/docs/latest/op-guide/recovery.html
  shell: |
    ETCDCTL_API=3 etcdctl --endpoints=https://{{ ansible_br_mgmt.ipv4.address }}:2379 --cacert=/etc/kubernetes/pki/etcd/ca.pem --key=/etc/kubernetes/pki/etcd/client-key.pem --cert=/etc/kubernetes/pki/etcd/client.pem snapshot restore /root{{ etcd_backup_latest_dir }}/snapshot.db --name {{ inventory_hostname }} --initial-cluster {{ initial_cluster }} --initial-cluster-token my-etcd-token --initial-advertise-peer-urls https://{{ ansible_br_mgmt.ipv4.address }}:2380 --data-dir /var/lib/etcd

- name: service restart on first master
  run_once: true
  ignore_errors: yes
  systemd:
    daemon_reload: yes
    name: etcd
    state: restarted
  when: "groups['all-masters'][0] == inventory_hostname"
  async: 45
  poll: 0

- pause:
    seconds: 10

- name: service restart on all other masters
  systemd:
    daemon_reload: yes
    name: etcd
    state: restarted
  when: "groups['all-masters'][0] != inventory_hostname"

#- name: Start etcd-member service on all etcd nodes
#  become: yes
#  service: name=etcd.service state=restarted

- name: Configure | Check if etcd cluster is healthy
  shell: "/usr/bin/etcdctl --ca-file /etc/kubernetes/pki/etcd/ca.pem --cert-file /etc/kubernetes/pki/etcd/client.pem --key-file /etc/kubernetes/pki/etcd/client-key.pem --peers https://{{ ansible_br_mgmt.ipv4.address }}:2379 cluster-health | grep -q 'cluster is healthy'"
  register: etcd_cluster_is_healthy
  ignore_errors: true
  changed_when: false
  check_mode: no
  until: etcd_cluster_is_healthy.rc == 0
  retries: 10
  delay: 5
